pbinom(1, size=10, prob=0.1)
dbinom(9, size=10, prob=0.9)
qnorm(.75,80,10) - qnorm(.25,80,10)
2.5/500
qnorm(10/100, 8.5/100 , 2.5/500)
1- pnorm(10, 8.5 , 2.5/5)
pbinom(1, size = 8, prob = 0.1)
dbinom(2,  size = 8, prob = 0.1) + dbinom(3,  size = 8, prob = 0.1)
pbinom(8, size = 8, prob = 0.1)
dbinom(8, size = 8, prob = 0.1)
1 – pbinom(15 , 125, 0.1)
pbinom(15 , 125, 0.1)
1- 0.8169
1- [pbinom(15 , 125, 0.1)]
pbinom(14 , 125, 0.1)
1- 0.7329886
pbinom(9 , 125, 0.1)
pbinom(9 , 125, 0.1)
pbinom(10 , 125, 0.1)
qnorm(0.8, 0.7, 0.21/ sqrt(50))
qnorm(0.2, 0.7, 0.21/ sqrt(50))
1- pnorm(0.8, 0.7, 0.21/ sqrt(50))
pnorm(0.8, 0.7, 0.21/ sqrt(50))
0.7 * 0.3
1- pnorm(0.8, 0.7, 0.21/ sqrt(50))
1- pnorm(0.5, 0.7, 0.21/ sqrt(50))
1- pnorm(0.8, 0.7, 0.21/ sqrt(50))
0.21/ sqrt(50)
0.1/0.02969848
sqrt(0.21)
a.	1 – pnorm(0.8 , 0.3 , 0.458/sqrt(50))
1 – pnorm(0.8 , 0.3 , 0.458/sqrt(50))
1–pnorm(0.8 , 0.3 , 0.458/sqrt(50))
1-pnorm(0.8 , 0.3 , 0.458/sqrt(50))
1-pnorm(0.8 , 0.7 , 0.458/sqrt(50))
1-pnorm(0.5 , 0.7 , 0.458/sqrt(50))
c <-
v <- c( 7, -5, -8, 7, 9, 12, 0, 3, 11, 8, 6, -2, 4)
order(v)
a.	Pbinom( 3, 5, 0.8)
pbinom( 3, 5, 0.8)
1 - 0.262
pbinom( 0, 5, 0.8)
qnorm(0.1, 20,4)
4/100
dbinom(0,20,0.04)
pbinom(0,20,0.04)
1- 0.4420024
qnorm(0.25, 11.90,40)
qnorm(0.25, 11.90,.40)
qnorm(0.25, 11.90,0.40)
1- 0.01
dbinom(5, 300, 0.01)
2.3/20
1-0.115
pbinom(2, 20, 0.115)
1- 0.59
4/60
1 - pexp(15,0.0666)
pbinom(18,45,0.33)
pbinom(18,45,0.33) - pbinom(9, 45, 0.33)
pbinom(17,45,0.33) - pbinom(9, 45, 0.33)
pbinom(9, 45, 0.33)
pbinom(18,45,0.33)
pbinom(18,45,0.33) - pbinom(9, 45, 0.33)
pbinom(18.5,45,0.33) - pbinom(8.5, 45, 0.33)
pbinom(40.5,45,0.33) - pbinom(19.5, 45, 0.33)
qnorm(85,70,8)
qnorm(0.85,70,8)
pbinom(10,125,0.1)
pbinom(9,125,0.1)
45/20
2.25/20
2.3/20
1 - pbinom(2,20, 0.115)
ppois(1,3/20)
dbinom(5,300, 0.01)
dexp(11,1/5) + dexp(12,1/5) + dexp(13,1/5) +dexp(14,1/5) + dexp(15,1/5)
1 - pbinom(3.5,0.8)
1 - pbinom(3,5,0.8)
ppois(2,8)
ppois(1,3/20)
qnorm(0.03,10,2)
1 - pexp(1,0.5)
pnorm(46,50,4)
1 - pnorm(46,50,4)
qnorm(46,50,4)
qnorm(0.46,50,4)
pnorm(46,50,4)
pnorm(29000,29321,2120/sqrt(100))
pnorm(215,220,15/sqrt(40))
rm(list = ls(all=TRUE))
pnorm(29000,29321,2120/sqrt(100))
pnorm(215,220,15/sqrt(40))
1.64 *
1.64 * 0.449
1.64*0.449
sqrt(880.4)
0.14583–1.96*sqrt(0.14583*0.854/1200)
0.14583 - 1.96*sqrt(0.14583*0.854/1200)
0.14583 + 1.96*sqrt(0.14583*0.854/1200)
pnorm(215,220,15/sqrt(40))
qnorm(0.05,lower.tail = F)
marginError <- qnorm(0.05,lower.tail = F)*4.49/10
49 - marginError
49 + marginError
z <- qnorm(0.025, lower.tail = F)
n <-
p <- 175/1200
q <- 1-p
p - 1.96*sqrt(p*q/1200)
p - 1.96*sqrt(p*q/1200)
p + 1.96*sqrt(p*q/1200)
lowerLimit <- p - 1.96*sqrt(p*q/1200)
UpperLimit <- p + 1.96*sqrt(p*q/1200)
n <- 35
mean <- 2.364
var <- 0.81
qt(0.05,34,lower.tail = F) // we have 34 degrees of freedom
qt(0.05,34,lower.tail = F) # we have 34 degrees of freedom
tvalue <- qt(0.05,34,lower.tail = F) # we have 34 degrees of freedom
2.364 - tvalue * 0.9
2.364 + tvalue * 0.9
2.364 - tvalue * 0.9/sqrt(35)
2.364 + tvalue * 0.9/sqrt(35)
qnorm(0.025,lower.tail = F)
z <-qnorm(0.025,lower.tail = F)
marginError <- qnorm(0.025,lower.tail = F)
lowerLimit <- 1014 - marginError*25/10
upperLimit <- 1014 + marginError*25/10
lowerLimit
upperLimit
marginError*25/10
n <- 36
z <- qnorm(0.025,lower.tail = F)
ME <- z * 0.3/sqrt(n)
lowerLimit <- 2.6 - ME
upperLimit <- 1014 + ME
lowerLimit,upperLimit
c(lowerLimit,upperLimit)
upperLimit <- 2.6 + ME
c(lowerLimit,upperLimit)
qnorm(0.05, lower.tail = F)
pnorm(1.164,9900,120/sqrt(30))
limitOnCriticalZone <- qnorm(0.05,lower.tail = F)
pnorm(9900,10000,120/sqrt(30))
options(scipen = pnorm(9900,10000,120/sqrt(30)))
options(scipen = pnorm(9900,10000,120/sqrt(30)))
x <- options(scipen = pnorm(9900,10000,120/sqrt(30)))
x
alpha <- 0.05
pnorm(9900,10000,120/sqrt(30)) # output 2.50
x <- options(scipen = 4)
pnorm(9900,10000,120/sqrt(30)) # output 2.50
x <- options(scipen = 5)
pnorm(9900,10000,120/sqrt(30)) # output 2.50
x <- options(scipen = 1)
pnorm(9900,10000,120/sqrt(30)) # output 2.50
x <- options(scipen = 2)
pnorm(9900,10000,120/sqrt(30)) # output 2.50
pnorm(9900,10000,120/sqrt(30)) # output 2.50
limitOnCriticalZone
actual <- pnorm(9900,10000,120/sqrt(30)) # output 0.000002505166
actual
As actual < limitOnCriticalZone, we can reject Manufacturer's claim
mean <- 10000
As actual < limitOnCriticalZone, we can reject Manufacturer's claim
mean <- 10000
n = 30
As actual < limitOnCriticalZone, we can reject Manufacturer's claim
mean <- 10000
n = 30
smean = 9900
As actual < limitOnCriticalZone, we can reject Manufacturer's claim
mean <- 10000
n = 30
smean = 9900
sd = 120
As actual < limitOnCriticalZone, we can reject Manufacturer's claim
mean <- 10000
n = 30
smean = 9900
sd = 120
zval <- (9900-10000)/(120/sqrt(30))
As actual < limitOnCriticalZone, we can reject Manufacturer's claim
mean <- 10000
n = 30
smean = 9900
sd = 120
zval <- (9900-10000)/(120/sqrt(30))
zval
sqrt(100*0.84*0.16)
1 - pnorm(80,84,3.67)
qnorm(p.95, lower.tail = F)
qnorm(0.95, lower.tail = F)
cal <- (80-84)/ sqrt(100*0.84*0.16)
cal <- (84-80)/ sqrt(100*0.84*0.16)
qnorm(0.95, lower.tail = F)
qnorm(0.95)
qnorm(0.025)
n <- 100
p <- 0.9
q <- 1- p
1 - pnorm(80.5, n*p, sqrt(n*p*q))
pnorm(80.5, n*p, sqrt(n*p*q))
qnorm(0.95, lower.tail = F)
qnorm(0.025)
75 - (8 /sqrt(16) * qnorm(0.25))
75 - (8 /sqrt(16) * qnorm(0.025))
75- (8 /sqrt(16) * qnorm(1-0.025))
75  + (8 /sqrt(16) * qnorm(0.025))
75 - (8 /sqrt(16) * qnorm(0.025))
75 - (8 /sqrt(16) * qnorm(0.025, lower.tail=F))
75  + (8 /sqrt(16) * qnorm(0.025, lower.tail=F))
qnorm(0.05)
1-pnorm(10,11,3/sqrt(40))
3/sqrt(40)
-1/0.474
q(0.05)
qnorm(0.05)
1-0.05
q(0.975)
qnorm(0.0025)
0.05/2
qnorm(0.025)
1.96*2
qnorm(0.10)
1.28*21/6
50-4.48
1 - pnorm(45, 43, 21/6)
1 - pnorm(45.31, 43, 21/6)
pnorm(78.92, 77, 2)
##--- Step 1: Clear environment variables ------------------------------------------##
rm(list=ls(all=T))
##--- Step 2: Set working Directory ------------------------------------------------##
setwd("E://Insofe//Week5//Day2//LAbWork//20171231_Batch37_CSE7302c_Lab01_SimpleLinReg_Lab")
getwd()
BigMacAll <- read.csv("BigMac-NetHourlyWage.csv", header = T, sep =",")
##--- Step 4: Perform Exploratory Data Analysis and Data Pre-processing-------------##
## Drop any irrelevant attribute(s):
BigMacAll <- subset(BigMacAll, select = -c(Country))
summary(BigMacAll)
BigMacAll[!complete.cases(BigMacAll$Big.Mac.Price....),]
BigMacAll[!complete.cases(BigMacAll$Net.Hourly.Wage....),]
## Correlation and Covariance between the attributes:
cov(BigMacAll)
cor(BigMacAll)
## Correlation and Covariance between the attributes:
cov(BigMacAll)
cor(BigMacAll)
#Describe how the covarainace and correlation coefficients are for the BigMac dataset
cor(BigMacAll$Big.Mac.Price....,BigMacAll$Net.Hourly.Wage....)
rows = seq(1,nrow(BigMacAll),1)
set.seed(44)
trainBigMacAllrows <- sample(rows,(80*nrow(BigMacAll))/100)
trainBigMacAll <- BigMacAll[trainBigMacAllrows,]
testBigMacAll <- BigMacAll[-trainBigMacAllrows,]
LinRegBigMacAll <- lm(Net.Hourly.Wage.... ~ Big.Mac.Price...., data = trainBigMacAll)
coefficients(LinRegBigMacAll)
summary(LinRegBigMacAll)
plot(trainBigMacAll$Big.Mac.Price...., trainBigMacAll$Net.Hourly.Wage....)
test <- testBigMacAll$Net.Hourly.Wage....
testBigMacAll$Net.Hourly.Wage.... <- NULL
test_prediction <- predict(LinRegBigMacAll, testBigMacAll)
test_prediction
#Error verification on train data
regr.eval(trainBigMacAll$Net.Hourly.Wage....,LinRegBigMacAll$fitted.values)
library(DMwR)
#Error verification on train data
regr.eval(trainBigMacAll$Net.Hourly.Wage....,LinRegBigMacAll$fitted.values)
#Error verification on test data
regr.eval(test,test_prediction)
cbind(test,test_prediction)
conf_pred <- data.frame(predict(LinRegBigMacAll, testBigMacAll, interval = "confidence", level = 0.95))
conf_pred
pred_pred <- data.frame(predict(LinRegBigMacAll, testBigMacAll, interval = "prediction", level = 0.95))
pred_pred
plot(testBigMacAll$Big.Mac.Price....,testBigMacAll$Net.Hourly.Wage...., xlab = "BigMac Price", ylab = "Net Hourly Wage")
conf_pred <- data.frame(predict(LinRegBigMacAll, testBigMacAll, interval = "confidence", level = 0.95))
plot(testBigMacAll$Big.Mac.Price....,testBigMacAll$Net.Hourly.Wage...., xlab = "BigMac Price", ylab = "Net Hourly Wage")
points(testBigMacAll$Big.Mac.Price....,conf_pred$fit,type="l", col="green", lwd=2)
rm(list=ls(all=TRUE))
#DIY Set directory and read the data
setwd("E:\Insofe\Week6\Day1\Lab\20180106_Batch37_CSE7302c_Multiple_Lin_Reg_Lab02\exercise")
#DIY Set directory and read the data
setwd("E://Insofe//Week6//Day1//Lab//20180106_Batch37_CSE7302c_Multiple_Lin_Reg_Lab02//exercise")
data<-read.csv("CustomerData.csv",header=T)
#DIY Data Exploration - Check Data Structure, and Summary
str(data)
#DIY Data Exploration - Check Data Structure, and Summary
str(data)
summary(data)
#DIY remove CustomerID Column
data <- subset(data, select=-c(Customer))
#DIY remove CustomerID Column
data <- subset(data, select=-c('Customer'))
#DIY remove CustomerID Column
data <- subset(data, select=-c('CustomerId'))
#DIY remove CustomerID Column
data <- subset(data, select=-c('CustomerID'))
#DIY remove CustomerID Column
data <- subset(data, select=-c(CustomerID))
data
#DIY convert City attribute as factor
data$City <- as.factor(data$City)
summary(data)
dataForModel = data
#DIY split the data into train and test data sets (70/30 Split)
rows = seq(1,nrow(dataForModel),1)
set.seed(123)
trainRows = sample(rows,(70*nrow(dataForModel))/100)
#DIY save train data to a dataframe named "train" and test data to a dataframe named "test"
train <- dataForModel[trainRows,]
test <- dataForModel[-trainRows,]
# Build model with all attributes into model.
# "TotalRevenueGenerated" is the target variable
?lm
LinReg1<- lm( TotalRevenueGenerated ~ ., data=train)
summary(LinReg1)
#Review the residual plots
par(mfrow=c(2,2))
plot(LinReg1)
plot(LinReg1,which=4)
par(mfrow=c(1,1)) #reset default
#Review the residual plots
par(mfrow=c(2,2))
plot(LinReg1)
# look at the residual and comment on them
# Do they  follow normal distribution?
#Yes except few values it follows normal distribution
# Look at the other residual plots and check
#Density of data is distributed properly, so it is normal distribution
# whether the linear regression assumptions are
# satisfied or not ?
hist(LinReg1$residuals)
# Error metrics evaluation on train data and test data
library(DMwR)
#Error verification on train data
regr.eval(train$TotalRevenueGenerated, LinReg1$fitted.values)
#Error verification on test data
target <- test$TotalRevenueGenerated
test$TotalRevenueGenerated <- NULL
test_prediction <- predict(LinReg1,test)
Pred<- regr.eval(test$TotalRevenueGenerated, test_prediction)
Pred
Pred<- regr.eval(target, test_prediction)
Pred
Pred
summary(LinReg1)
LinReg2 <- lm(TotalRevenueGenerated ~ City2 + NoOfChildren + MinAgeOfChild + FrquncyOfPurchase
+ NoOfUnitsPurchased + FrequencyOFPlay + NoOfGamesBought
+ FavoriteChannelOfTransactionUniform + FavoriteGameUniform, data = train)
LinReg2 <- lm(TotalRevenueGenerated ~ City + NoOfChildren + MinAgeOfChild + FrquncyOfPurchase
+ NoOfUnitsPurchased + FrequencyOFPlay + NoOfGamesBought
+ FavoriteChannelOfTransactionUniform + FavoriteGameUniform, data = train)
LinReg2 <- lm(TotalRevenueGenerated ~ City + NoOfChildren + MinAgeOfChild + FrquncyOfPurchase
+ NoOfUnitsPurchased + FrequencyOFPlay + NoOfGamesBought
+ FavoriteChannelOfTransaction + FavoriteGame, data = train)
#In LinReg1 observe the significant values
summary(LinReg2)
par(mfrow=c(2,2))
plot(LinReg2)
regr.eval(train$TotalRevenueGenerated, LinReg2$fitted.values)
test
test
test_prediction2 <- predict(LinReg2,test)
test_prediction2
pred2 <- regr.eval(test,test_prediction2)
test
test_prediction2 <- predict(LinReg2,test)
test_prediction2
pred2 <- regr.eval(test,test_prediction2)
pred2 <- regr.eval(target,test_prediction2)
pred2
#Review the residual plots
par(mfrow=c(2,2))
plot(LinReg1)
#In LinReg1 observe the significant values
summary(LinReg2)
####################################################
#Scaling the data
library(vegan)
####################################################
#Scaling the data
library(vegan)
str(data)
data_cat <- data[,c(1,11,12)]
data_num <- data[,-c(1,11,12)]
pred2
#Error verification on test data
target <- test$TotalRevenueGenerated
target
rm(list=ls(all=TRUE))
#DIY Set directory and read the data
setwd("E://Insofe//Week6//Day1//Lab//20180106_Batch37_CSE7302c_Multiple_Lin_Reg_Lab02//exercise")
data<-read.csv("CustomerData.csv",header=T)
#DIY Data Exploration - Check Data Structure, and Summary
str(data)
summary(data)
#DIY remove CustomerID Column
data <- subset(data, select=-c(CustomerID))
dataForModel = data
#DIY convert City attribute as factor
data$City <- as.factor(data$City)
#DIY split the data into train and test data sets (70/30 Split)
rows = seq(1,nrow(dataForModel),1)
set.seed(123)
trainRows = sample(rows,(70*nrow(dataForModel))/100)
#DIY save train data to a dataframe named "train" and test data to a dataframe named "test"
train <- dataForModel[trainRows,]
test <- dataForModel[-trainRows,]
LinReg1<- lm( TotalRevenueGenerated ~ ., data=train)
summary(LinReg1)
#Review the residual plots
par(mfrow=c(2,2))
# Error metrics evaluation on train data and test data
library(DMwR)
#Error verification on train data
regr.eval(train$TotalRevenueGenerated, LinReg1$fitted.values)
#Error verification on test data
target <- test$TotalRevenueGenerated
target
test$TotalRevenueGenerated <- NULL
test_prediction <- predict(LinReg1,test)
Pred<- regr.eval(target, test_prediction)
Pred
summary(LinReg1)
LinReg2 <- lm(TotalRevenueGenerated ~ City + NoOfChildren + MinAgeOfChild + FrquncyOfPurchase
+ NoOfUnitsPurchased + FrequencyOFPlay + NoOfGamesBought
+ FavoriteChannelOfTransaction + FavoriteGame, data = train)
#In LinReg1 observe the significant values
summary(LinReg2)
regr.eval(train$TotalRevenueGenerated, LinReg2$fitted.values)
test
test_prediction2 <- predict(LinReg2,test)
pred2 <- regr.eval(target,test_prediction2)
pred2
data_num
####################################################
#Scaling the data
library(vegan)
str(data)
data_cat <- data[,c(1,11,12)]
data_num <- data[,-c(1,11,12)]
data_num
summary(data_num)
# Apply standardization. Ensure , you exclude the target variable
#during standardization
data_num_subset <- subset(data_num, select = -c(TotalRevenueGenerated))
# Apply standardization. Ensure , you exclude the target variable
#during standardization
data_num <- subset(data_num, select = -c(TotalRevenueGenerated))
# Apply standardization. Ensure , you exclude the target variable
#during standardization
rm(data_num_subset)
# Apply standardization. Ensure , you exclude the target variable
#during standardization
#rm(data_num_subset)
data_num_std <- decostand(subset(data_num, select=-c(TotalRevenueGenerated),"standardize")
data_num_std
data_cat <- data[,c(1,11,12)]
data_num <- data[,-c(1,11,12)]
summary(data_num)
# Apply standardization. Ensure , you exclude the target variable
#during standardization
#rm(data_num_subset)
data_num_std <- decostand(subset(data_num, select=-c(TotalRevenueGenerated),"standardize")
data_num_std
####################################################
#Scaling the data
library(vegan)
str(data)
data_cat <- data[,c(1,11,12)]
data_num <- data[,-c(1,11,12)]
# Apply standardization. Ensure , you exclude the target variable
#during standardization
#rm(data_num_subset)
data_num_std <- decostand(subset(data_num, select=-c(TotalRevenueGenerated),"standardize"))
# Apply standardization. Ensure , you exclude the target variable
#during standardization
#rm(data_num_subset)
data_num_std <- decostand(subset(data_num, select=-c(TotalRevenueGenerated)),"standardize")
data_num_std
#Combine standardized attributes back with the
# categorical attributes
data_std_final <- cbind(data_num_std,data_cat)
class(data_std_final)
data_std_final <- cbind(data_std_final, data_num$TotalRevenueGenerated)
data_std_final
class(TotalRevenueGenerated)
class(data_std_final)
View(data_std_final)
colnames(data_std_final)[ncol(data_std_final)] <- "TotalRevenueGenerated"
View(data_std_final)
#Split the data into train(70%) and test data sets
rows= seq(1, nrow(data_std_final),1)
set.seed(123)
trainRows= sample(rows,(70*nrow(data_std_final))/100)
train_std = data_std_final[trainRows,]
test_std = data_std_final[-trainRows,]
# Build linear regression with all attributes
LinReg_std1 <- lm(TotalRevenueGenerated~., data=train_std)
summary(LinReg_std1)
#Error verification on train data
regr.eval(train_std$TotalRevenueGenerated,LinReg_std1$fitted.values)
test
test_prediction_std1 <- predict(LinReg_std1, test)
#Error verification on test data
target_std <- test_std$TotalRevenueGenerated
test_prediction_std1 <- predict(LinReg_std1, test_std)
pred_Std1 <- regr.eval(target_std,test_prediction_std1)
pred_Std1
